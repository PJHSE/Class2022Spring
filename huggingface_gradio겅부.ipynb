{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huggingface_gradio.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PJHSE/Class2022Spring/blob/main/huggingface_gradio%EA%B2%85%EB%B6%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YIc3wBXqPoAi",
        "outputId": "cc5f9daa-92bc-4da6-c15b-0c3d53c41fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 analytics-python-1.4.0 anyio-3.6.1 asgiref-3.5.2 async-timeout-4.0.2 asynctest-0.13.0 backoff-1.10.0 bcrypt-3.2.2 cryptography-37.0.2 fastapi-0.78.0 ffmpy-0.3.0 frozenlist-1.3.0 gradio-3.0.14 h11-0.13.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.0 mdurl-0.1.1 monotonic-1.6 multidict-6.0.2 orjson-3.7.2 paramiko-2.11.0 pycryptodome-3.14.1 pydantic-1.9.1 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 sniffio-1.2.0 starlette-0.19.1 uc-micro-py-1.0.1 uvicorn-0.17.6 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Image classification](https://huggingface.co/tasks/image-classification)"
      ],
      "metadata": {
        "id": "HiGiIwHHXyJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/google/vit-base-patch16-224 \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "N85f15SRXtON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gJatB6PFZdse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "# model predicts one of the 1000 ImageNet classes\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "ldZauC4yXfBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "CR7IwXS5Ybbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (image):\n",
        "  feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "  model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "  inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  # model predicts one of the 1000 ImageNet classes\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  predicted_class = model.config.id2label[predicted_class_idx]\n",
        "  return predicted_class"
      ],
      "metadata": {
        "id": "CA35L2ZPZveq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/tiger.jpg\"\n",
        "os.system(\"curl \" + url + \" > tiger.jpg\")\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/dog.jpg\"\n",
        "os.system(\"curl \" + url + \" > dog.jpg\")"
      ],
      "metadata": {
        "id": "v4FSg0gMbBLJ",
        "outputId": "ae0263f9-afbc-4294-b369-fbdb2824a0e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='image', outputs='text', examples = ['tiger.jpg', 'dog.jpg']).launch()"
      ],
      "metadata": {
        "id": "h3N3dCkG2o3j",
        "outputId": "e1c46d02-6781-46ce-a2f3-b8103e34dd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://43269.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://43269.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f0fe1aa63d0>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://43269.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Fill-Mask](https://huggingface.co/tasks/fill-mask)"
      ],
      "metadata": {
        "id": "Z8kY0va6YuS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/bert-base-uncased \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "IGD_q0SXfCF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zR23S_FtfIkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "unmasker(\"Hello I'm a [MASK] model.\")"
      ],
      "metadata": {
        "id": "spM_LYGees_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "KaobDkL0fRJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "def func (text):\n",
        "  unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "  result = unmasker(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  return df"
      ],
      "metadata": {
        "id": "3CKQl_oDfTsd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"Hello I'm a [MASK] model.\", \"It is raining outside. I feel [MASK].\"]"
      ],
      "metadata": {
        "id": "-OkQDYW2wju6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1aGFWiTUfl9r",
        "outputId": "b23c3f5c-adfe-4a22-8d4d-3a112244d322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://15698.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://15698.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f0fe1870890>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://15698.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Token classification](https://huggingface.co/tasks/token-classification)"
      ],
      "metadata": {
        "id": "0DDckwQ50cRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/dslim/bert-base-NER \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "mxv4tEUM0y_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hUVn8h1304DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."
      ],
      "metadata": {
        "id": "9ksySb1Q50wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"My name is Wolfgang and I live in Berlin\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "id": "d9UOCPGJ0b1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "1CuE0WLi0x7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "def func (text):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "  nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "  result = nlp(text)\n",
        "  df = pd.DataFrame(result)\n",
        "  return df"
      ],
      "metadata": {
        "id": "jlx5iyV_0xV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\"My name is Wolfgang and I live in Berlin\", \"I will visit Seoul to see Chris\"]"
      ],
      "metadata": {
        "id": "upMTUXmc4fip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs='text', outputs='dataframe', examples = examples).launch()"
      ],
      "metadata": {
        "id": "Nes4r_Ek4fYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Sentence similarity](https://huggingface.co/tasks/sentence-similarity)"
      ],
      "metadata": {
        "id": "dE0umBRo7knv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.g. https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \\\n",
        "How to use"
      ],
      "metadata": {
        "id": "WJByl36a7lbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "lZvWkGmwAasZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sentences = [\"This is an example sentence\", \"it is one example writing\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "ahXHjR-x7nP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[1])"
      ],
      "metadata": {
        "id": "z9tLd396Hthr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "cosine_scores"
      ],
      "metadata": {
        "id": "Ne5AH2qbCZy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo in Gradio"
      ],
      "metadata": {
        "id": "As33TUuTcJH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func (text1, text2):\n",
        "  from sentence_transformers import SentenceTransformer, util\n",
        "  model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "  embeddings = model.encode([text1, text2])\n",
        "  cosine_scores = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "  return cosine_scores"
      ],
      "metadata": {
        "id": "XqwC0HHicM71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [[\"This is an example sentence\", \"it is one example writing\"], [\"A frog is hopping near the pond\", \"I love Korean Food\"]]"
      ],
      "metadata": {
        "id": "zZMVURDWcTNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=func, inputs=['text', 'text'], outputs='number', examples = examples).launch()"
      ],
      "metadata": {
        "id": "1pbOXexycTGR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}